{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xml_data(reviews, idx, data):\n",
    "    review = ET.SubElement(reviews, 'review')\n",
    "    review.set('id', str(idx))\n",
    "    \n",
    "    app_ver = ET.SubElement(review, 'app_version')\n",
    "    app_ver.text = '0.0'\n",
    "    \n",
    "    user = ET.SubElement(review, 'user')\n",
    "    user.text = 'NA'\n",
    "    \n",
    "    date = ET.SubElement(review, 'date')\n",
    "    date.text = '1970-01-01'\n",
    "    \n",
    "    review_title = ET.SubElement(review, 'review_title')\n",
    "    review_title.text = ''\n",
    "    \n",
    "    review_text = ET.SubElement(review, 'review_text')\n",
    "    review_text.text = data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the central repo that holds all the raw feedback data\n",
    "raw_data_dir = \"./data/raw\"\n",
    "\n",
    "# Get the central repo that will hold all the XML\n",
    "xml_data_dir = \"./data/xml\"\n",
    "\n",
    "os.makedirs(xml_data_dir, exist_ok=True)\n",
    "\n",
    "# Read the files one by one, exporting them to xml\n",
    "for dataset in os.listdir(raw_data_dir):\n",
    "    df = pd.read_csv(os.path.join(raw_data_dir, dataset), index_col = 0)\n",
    "    df.labels = df.labels.str.strip(\"']\").str.strip(\"['\").str.split(\",\")\n",
    "    \n",
    "    # create the file structure\n",
    "    reviews = ET.Element('reviews')\n",
    "    \n",
    "    for idx, data in df.to_dict(\"index\").items():\n",
    "        get_xml_data(reviews, idx, data)\n",
    "        \n",
    "    review_xml_str = ET.tostring(reviews)\n",
    "    \n",
    "    dataset_name = dataset[:-4]\n",
    "        \n",
    "    dataset_name = dataset_name.replace(\" \", \"_\").replace(\"#\", \"_\")\n",
    "\n",
    "    with open(os.path.join(xml_data_dir, f\"{dataset_name}.xml\"), \"w\") as xml_file:\n",
    "        xml_file.write(review_xml_str.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a script to run this in SURF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_str = lambda x: f\"\"\"java -classpath \"C:\\\\Users\\\\pdev438\\\\shared\\\\panichella-SURF-tool-adcc79b\\\\SURF-Tool\\\\SURF-Tool\\\\lib\\\\*;C:\\\\Users\\\\pdev438\\\\shared\\\\panichella-SURF-tool-adcc79b\\\\SURF-Tool\\\\SURF-Tool\\\\SURF.jar\" org.surf.Main C:\\\\Users\\\\pdev438\\\\projects\\\\unsupervised-classification-benchmark\\\\data\\\\xml\\\\{x}.xml {x}.xml \\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"run_surf.bat\", \"w\") as f:\n",
    "    cmd_str_text = \"\"\n",
    "    for dataset_name in os.listdir(raw_data_dir):\n",
    "        \n",
    "        dataset_name = dataset_name[:-4].replace(\" \", \"_\")\n",
    "        \n",
    "        cmd_str_text += cmd_str(dataset_name)\n",
    "    f.write(cmd_str_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the SURF model over this xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pd.read_csv(os.path.join(\"./data/raw\", \"williams_2017_@snapchat.csv\"), index_col = 0).labels.str.split(\",\").apply(lambda x: x[0]).unique()\n",
    "\n",
    "# df = pd.read_csv(os.path.join(\"./data/raw\", \"tizard_2019_features.csv\"), index_col = 0)\n",
    "# df.labels = df.labels.str.strip(\"]\").str.strip(\"[\").str.split(\",\")\n",
    "# df.labels = df.labels.apply(lambda labels: [label.strip(\"\\\"\").strip(\"'\") for label in labels])\n",
    "# print(df.shape)\n",
    "# df.labels.apply(lambda x: x[0]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_maps = {\n",
    "    \"chen_2014\": [([\"informative\"], [\"BUG\", 'REQUEST', 'INFO', 'QUESTION'])],\n",
    "    \"ciurumelea_2017\": [([\"OTHER\"], [\"OTHER\"])],\n",
    "    \"di_sorbo_2016\": [([\"[INFO]\"], [\"INFO\"]), ([\"[BUG]\"], [\"BUG\"]), ([\"[REQUEST]\"], [\"REQUEST\"]), ([\"[QUESTION]\"], [\"QUESTION\"])],\n",
    "    \"guzman_2015\": [([\"Bug report\"], [\"BUG\"]), ([\"User request\"], [\"REQUEST\"])],\n",
    "    \"maalej_2016\": [([\"Bug\"], [\"BUG\"]), ([\"Feature\"], [\"REQUEST\"])],\n",
    "    \"scalabrino_2017\": [([\"BUG\"], [\"BUG\"]), ([\"FEATURE\"], [\"REQUEST\"])],\n",
    "    \"tizard_2019\": [([\"apparent bug\"], [\"BUG\"]), ([\"feature request\"], [\"REQUEST\"]), ([\"question on application\", \"help seeking\", \"requesting more information\", \"question on background\"], [\"QUESTION\"]), ([\"application guidance\", \"user setup\", \"praise for application\", \"dispraise for application\", \"application usage\", \"attempted solution\", \"acknowledgement of problem resolution\"], [\"INFO\"])],\n",
    "    \"williams_2017\": [([\"bug\"], [\"BUG\"]), ([\"fea\"], [\"REQUEST\"]), ([\"oth\"], [\"OTHER\"])],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chen_2014_facebook.xml\n",
      "chen_2014_swiftkey.xml\n",
      "chen_2014_tapfish.xml\n",
      "chen_2014_templerun2.xml\n",
      "ciurumelea_2017_2048.xml\n",
      "ciurumelea_2017_Calculator.xml\n",
      "ciurumelea_2017_CatLog.xml\n",
      "ciurumelea_2017_Wally.xml\n",
      "ciurumelea_2017_Xabber.xml\n",
      "di_sorbo_2016_blinq_summary.xml\n",
      "di_sorbo_2016_cstp_summary.xml\n",
      "di_sorbo_2016_doodlePairs_summary.xml\n",
      "di_sorbo_2016_karaokeFree_summary.xml\n",
      "di_sorbo_2016_lifelog_summary.xml\n",
      "di_sorbo_2016_minesweeperReloaded_summary.xml\n",
      "di_sorbo_2016_movieCreator_summary.xml\n",
      "di_sorbo_2016_picturexAndroid_summary.xml\n",
      "di_sorbo_2016_picturexWindowsPhone_summary.xml\n",
      "di_sorbo_2016_sheepOblock_summary.xml\n",
      "di_sorbo_2016_sketch_summary.xml\n",
      "di_sorbo_2016_stoneFlood_summary.xml\n",
      "di_sorbo_2016_trackID_summary.xml\n",
      "di_sorbo_2016_video_summary.xml\n",
      "di_sorbo_2016_weightTrack_summary.xml\n",
      "di_sorbo_2016_wifiFileTransfer_summary.xml\n",
      "guzman_2015_Evernote.xml\n",
      "guzman_2015_Picsart.xml\n",
      "guzman_2015_Pininterest.xml\n",
      "guzman_2015_Tripadvisor.xml\n",
      "guzman_2015_Whatsapp.xml\n",
      "maalej_2016_310947683.xml\n",
      "maalej_2016_403692190.xml\n",
      "scalabrino_2017_acr.browser.barebones.xml\n",
      "scalabrino_2017_air.hmbtned.xml\n",
      "scalabrino_2017_com.alfray.timeriffic.xml\n",
      "scalabrino_2017_com.duckduckgo.mobile.android.xml\n",
      "scalabrino_2017_com.google.zxing.client.android.xml\n",
      "scalabrino_2017_com.ringdroid.xml\n",
      "scalabrino_2017_com.uberspot.a2048.xml\n",
      "scalabrino_2017_com.viber.voip.xml\n",
      "scalabrino_2017_edu.berkeley.boinc.xml\n",
      "scalabrino_2017_org.dolphinemu.dolphinemu.xml\n",
      "scalabrino_2017_org.linphone.xml\n",
      "scalabrino_2017_org.wordpress.android.xml\n",
      "tizard_2019_features.xml\n",
      "tizard_2019_issue.xml\n",
      "williams_2017_@android.xml\n",
      "williams_2017_@applesupport.xml\n",
      "williams_2017_@googlechrome.xml\n",
      "williams_2017_@instagram.xml\n",
      "williams_2017_@minecraft.xml\n",
      "williams_2017_@snapchat.xml\n",
      "williams_2017_@visualstudio.xml\n",
      "williams_2017_@whatsapp.xml\n",
      "williams_2017_@windows.xml\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "results = {}\n",
    "XML_dir = \"C:\\\\Users\\\\pdev438\\\\shared\\\\panichella-SURF-tool-adcc79b\\\\SURF-Tool\\\\SURF-Tool\\\\demo-data-set\\\\\"\n",
    "\n",
    "for file in os.listdir(XML_dir):\n",
    "    \n",
    "    if file[-4:] != \".xml\":\n",
    "        continue\n",
    "    print(file)\n",
    "\n",
    "    xml_file_dir = os.path.join(XML_dir, file)\n",
    "\n",
    "    with open(xml_file_dir, \"r\", encoding=\"utf-8\") as f:\n",
    "        xml_str_data = f.read()\n",
    "        root = ET.fromstring(xml_str_data)\n",
    "\n",
    "    labelled_sentences = []\n",
    "\n",
    "    [labelled_sentences.extend(x.find(\"sentences\").findall(\"sentence\")) for x in root.findall(\"topic\")]\n",
    "\n",
    "    feedback_labels = {}\n",
    "\n",
    "    def extract_labels_for_sentences(sentence_tag):\n",
    "        label = sentence_tag.find(\"sentence_type\").text\n",
    "        origin_id = sentence_tag.find(\"from_review\").text\n",
    "\n",
    "        if origin_id in feedback_labels.keys():\n",
    "            feedback_labels[origin_id].append(label)\n",
    "        else:\n",
    "            feedback_labels[origin_id] = [label]\n",
    "\n",
    "    [extract_labels_for_sentences(x) for x in labelled_sentences]\n",
    "\n",
    "    feedback_labels = {k: list(set(v)) for k,v in feedback_labels.items()}\n",
    "\n",
    "    # Get the central repo that holds all the raw feedback data\n",
    "    raw_data_dir = \"./data/raw\"\n",
    "    \n",
    "    csv_file_name = file[:-4] + \".csv\"\n",
    "\n",
    "    df = pd.read_csv(os.path.join(raw_data_dir, csv_file_name), index_col = 0)\n",
    "    df.labels = df.labels.str.strip(\"]\").str.strip(\"[\").str.split(\",\")\n",
    "    df.labels = df.labels.apply(lambda labels: [label.strip(\"\\\"\").strip(\"'\") for label in labels])\n",
    "    df.labels = df.labels.apply(lambda labels: [label.replace(\"'\", \"\").replace(\"\\\"\", \"\").strip() for label in labels])\n",
    "    \n",
    "    dataset_name = [dataset for dataset in label_maps.keys() if dataset in file][0]\n",
    "    label_map = label_maps[dataset_name]\n",
    "    \n",
    "    true_label_set = [labels[0] for labels in label_map]\n",
    "    prediction_label_set = [labels[1] for labels in label_map]\n",
    "    \n",
    "    df[\"surf_labels\"] = None\n",
    "    \n",
    "    for index, labels in feedback_labels.items():\n",
    "        df.loc[int(index), \"surf_labels\"] = labels\n",
    "        \n",
    "    df[\"surf_labels\"] = df[\"surf_labels\"].apply(lambda x: [\"OTHER\"] if x is None else x)\n",
    "    \n",
    "    true_labels = df.labels.apply(lambda x: [any([true_label in x for true_label in true_label_list]) for true_label_list in true_label_set])\n",
    "    pred_labels = df.surf_labels.apply(lambda x: [any([pred_label in x for pred_label in prediction_label_list]) for prediction_label_list in prediction_label_set])\n",
    "    \n",
    "    true_lab_arr = np.asarray(true_labels.values.reshape(-1).tolist())\n",
    "    pred_lab_arr = np.asarray(pred_labels.values.reshape(-1).tolist())\n",
    "    \n",
    "    # Only find ROC AUC value of labels that are contained in true labels\n",
    "    class_has_true_values = true_lab_arr.any(axis=0)\n",
    "    \n",
    "    true_lab_arr = true_lab_arr[:, class_has_true_values]\n",
    "    pred_lab_arr = pred_lab_arr[:, class_has_true_values]\n",
    "    \n",
    "    roc_auc_score_val = roc_auc_score(true_lab_arr, pred_lab_arr)\n",
    "    \n",
    "    results[file[:-4]] = roc_auc_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chen_2014_facebook': 0.5694599231371626,\n",
       " 'chen_2014_swiftkey': 0.5865985756093035,\n",
       " 'chen_2014_tapfish': 0.5872852355468396,\n",
       " 'chen_2014_templerun2': 0.5922563541777374,\n",
       " 'ciurumelea_2017_2048': 0.5625,\n",
       " 'ciurumelea_2017_Calculator': 0.6017374517374516,\n",
       " 'ciurumelea_2017_CatLog': 0.6254901960784314,\n",
       " 'ciurumelea_2017_Wally': 0.6071428571428571,\n",
       " 'ciurumelea_2017_Xabber': 0.5,\n",
       " 'di_sorbo_2016_blinq_summary': 0.8130252485609628,\n",
       " 'di_sorbo_2016_cstp_summary': 0.8571428571428572,\n",
       " 'di_sorbo_2016_doodlePairs_summary': 0.9285714285714286,\n",
       " 'di_sorbo_2016_karaokeFree_summary': 0.9131944444444444,\n",
       " 'di_sorbo_2016_lifelog_summary': 0.8535632183908046,\n",
       " 'di_sorbo_2016_minesweeperReloaded_summary': 0.8870214752567693,\n",
       " 'di_sorbo_2016_movieCreator_summary': 0.8902207288835196,\n",
       " 'di_sorbo_2016_picturexAndroid_summary': 0.9285714285714286,\n",
       " 'di_sorbo_2016_picturexWindowsPhone_summary': 0.875,\n",
       " 'di_sorbo_2016_sheepOblock_summary': 0.921875,\n",
       " 'di_sorbo_2016_sketch_summary': 0.8791666666666667,\n",
       " 'di_sorbo_2016_stoneFlood_summary': 0.7709854832618788,\n",
       " 'di_sorbo_2016_trackID_summary': 0.8578853332939049,\n",
       " 'di_sorbo_2016_video_summary': 0.8592307297973969,\n",
       " 'di_sorbo_2016_weightTrack_summary': 0.9055555555555556,\n",
       " 'di_sorbo_2016_wifiFileTransfer_summary': 0.914546783625731,\n",
       " 'guzman_2015_Evernote': 0.7002319680777889,\n",
       " 'guzman_2015_Picsart': 0.6649334220416159,\n",
       " 'guzman_2015_Pininterest': 0.6800356935718577,\n",
       " 'guzman_2015_Tripadvisor': 0.6581027091687739,\n",
       " 'guzman_2015_Whatsapp': 0.6796612898793524,\n",
       " 'maalej_2016_310947683': 1.0,\n",
       " 'maalej_2016_403692190': 0.5,\n",
       " 'scalabrino_2017_acr.browser.barebones': 0.6446428571428572,\n",
       " 'scalabrino_2017_air.hmbtned': 0.5729166666666666,\n",
       " 'scalabrino_2017_com.alfray.timeriffic': 0.7333333333333334,\n",
       " 'scalabrino_2017_com.duckduckgo.mobile.android': 0.5357808857808858,\n",
       " 'scalabrino_2017_com.google.zxing.client.android': 0.6717414529914529,\n",
       " 'scalabrino_2017_com.ringdroid': 0.6023601398601399,\n",
       " 'scalabrino_2017_com.uberspot.a2048': 0.75,\n",
       " 'scalabrino_2017_com.viber.voip': 0.5197947214076246,\n",
       " 'scalabrino_2017_edu.berkeley.boinc': 0.5342320261437908,\n",
       " 'scalabrino_2017_org.dolphinemu.dolphinemu': 0.5723134708428825,\n",
       " 'scalabrino_2017_org.linphone': 0.5681623931623931,\n",
       " 'scalabrino_2017_org.wordpress.android': 0.7001633986928104,\n",
       " 'tizard_2019_features': 0.5886219160351085,\n",
       " 'tizard_2019_issue': 0.5622292578062555,\n",
       " 'williams_2017_@android': 0.5999575263577325,\n",
       " 'williams_2017_@applesupport': 0.6254155691248102,\n",
       " 'williams_2017_@googlechrome': 0.6001135516893469,\n",
       " 'williams_2017_@instagram': 0.5980235779520585,\n",
       " 'williams_2017_@minecraft': 0.6432079917299842,\n",
       " 'williams_2017_@snapchat': 0.5488527794790494,\n",
       " 'williams_2017_@visualstudio': 0.5805517515442169,\n",
       " 'williams_2017_@whatsapp': 0.640692615020336,\n",
       " 'williams_2017_@windows': 0.5722567232574112}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chen_2014_swiftkey.csv'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"surf_labels\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, labels in feedback_labels.items():\n",
    "    df.loc[int(index), \"surf_labels\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"surf_labels\"] = df[\"surf_labels\"].apply(lambda x: [\"OTHER\"] if x is None else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OTHER', 'BUG', 'REQUEST', 'INFO', 'QUESTION'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.surf_labels.apply(lambda x: x[0]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non-informative', 'informative'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.apply(lambda x: x[0]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_bugs = df.labels.apply(lambda x: [\"informative\" in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bugs = df.surf_labels.apply(lambda x: [\"OTHER\" not in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5694599231371626"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(np.asarray(true_bugs.values.reshape(-1).tolist()), np.asarray(pred_bugs.values.reshape(-1).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
