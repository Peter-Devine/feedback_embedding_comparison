{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xml_data(reviews, idx, data):\n",
    "    review = ET.SubElement(reviews, 'review')\n",
    "    review.set('id', str(idx))\n",
    "    \n",
    "    app_ver = ET.SubElement(review, 'app_version')\n",
    "    app_ver.text = '0.0'\n",
    "    \n",
    "    user = ET.SubElement(review, 'user')\n",
    "    user.text = 'NA'\n",
    "    \n",
    "    date = ET.SubElement(review, 'date')\n",
    "    date.text = '1970-01-01'\n",
    "    \n",
    "    review_title = ET.SubElement(review, 'review_title')\n",
    "    review_title.text = ''\n",
    "    \n",
    "    review_text = ET.SubElement(review, 'review_text')\n",
    "    review_text.text = data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the central repo that holds all the raw feedback data\n",
    "raw_data_dir = \"./data/raw\"\n",
    "\n",
    "# Get the central repo that will hold all the XML\n",
    "xml_data_dir = \"./data/xml\"\n",
    "\n",
    "os.makedirs(xml_data_dir, exist_ok=True)\n",
    "\n",
    "# Read the files one by one, exporting them to xml\n",
    "for dataset in os.listdir(raw_data_dir):\n",
    "    df = pd.read_csv(os.path.join(raw_data_dir, dataset), index_col = 0)\n",
    "    df.labels = df.labels.str.strip(\"']\").str.strip(\"['\").str.split(\",\")\n",
    "    \n",
    "    # create the file structure\n",
    "    reviews = ET.Element('reviews')\n",
    "    \n",
    "    for idx, data in df.to_dict(\"index\").items():\n",
    "        get_xml_data(reviews, idx, data)\n",
    "        \n",
    "    review_xml_str = ET.tostring(reviews)\n",
    "    \n",
    "    dataset_name = dataset[:-4]\n",
    "        \n",
    "    dataset_name = dataset_name.replace(\" \", \"_\").replace(\"#\", \"_\")\n",
    "\n",
    "    with open(os.path.join(xml_data_dir, f\"{dataset_name}.xml\"), \"w\") as xml_file:\n",
    "        xml_file.write(review_xml_str.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a script to run this in SURF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donload SURF from https://zenodo.org/record/165128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_unzip_dir = \"D:\\\\peter_devine_projects\\\\SURF-tool-SURF-v1.0\\\\panichella-SURF-tool-adcc79b\"\n",
    "xml_absolute_data_dir = \"D:\\\\peter_devine_projects\\\\unsupervised-classification-benchmark\\\\data\\\\xml\"\n",
    "\n",
    "cmd_str = lambda x: f\"\"\"java -classpath \"{surf_unzip_dir}\\\\SURF-Tool\\\\SURF-Tool\\\\lib\\\\*;{surf_unzip_dir}\\\\SURF-Tool\\\\SURF-Tool\\\\SURF.jar\" org.surf.Main {xml_absolute_data_dir}\\\\{x}.xml {x}.xml \\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"run_surf.bat\", \"w\") as f:\n",
    "    cmd_str_text = \"\"\n",
    "    for dataset_name in os.listdir(raw_data_dir):\n",
    "        \n",
    "        dataset_name = dataset_name[:-4].replace(\" \", \"_\").replace(\"#\", \"_\")\n",
    "        \n",
    "        cmd_str_text += cmd_str(dataset_name)\n",
    "    f.write(cmd_str_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the run_surf.bat file that is now in your cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the SURF model over this xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pd.read_csv(os.path.join(\"./data/raw\", \"williams_2017_@snapchat.csv\"), index_col = 0).labels.str.split(\",\").apply(lambda x: x[0]).unique()\n",
    "\n",
    "# df = pd.read_csv(os.path.join(\"./data/raw\", \"tizard_2019_features.csv\"), index_col = 0)\n",
    "# df.labels = df.labels.str.strip(\"]\").str.strip(\"[\").str.split(\",\")\n",
    "# df.labels = df.labels.apply(lambda labels: [label.strip(\"\\\"\").strip(\"'\") for label in labels])\n",
    "# print(df.shape)\n",
    "# df.labels.apply(lambda x: x[0]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_maps = {\n",
    "    \"chen_2014\": [([\"informative\"], [\"BUG\", 'REQUEST', 'INFO', 'QUESTION'])],\n",
    "    \"ciurumelea_2017\": [([\"OTHER\"], [\"OTHER\"])],\n",
    "    \"di_sorbo_2016\": [([\"[INFO]\"], [\"INFO\"]), ([\"[BUG]\"], [\"BUG\"]), ([\"[REQUEST]\"], [\"REQUEST\"]), ([\"[QUESTION]\"], [\"QUESTION\"])],\n",
    "    \"guzman_2015\": [([\"Bug report\"], [\"BUG\"]), ([\"User request\"], [\"REQUEST\"])],\n",
    "    \"maalej_2016\": [([\"Bug\"], [\"BUG\"]), ([\"Feature\"], [\"REQUEST\"])],\n",
    "    \"scalabrino_2017\": [([\"BUG\"], [\"BUG\"]), ([\"FEATURE\"], [\"REQUEST\"])],\n",
    "    \"tizard_2019\": [([\"apparent bug\"], [\"BUG\"]), ([\"feature request\"], [\"REQUEST\"]), ([\"question on application\", \"help seeking\", \"requesting more information\", \"question on background\"], [\"QUESTION\"]), ([\"application guidance\", \"user setup\", \"praise for application\", \"dispraise for application\", \"application usage\", \"attempted solution\", \"acknowledgement of problem resolution\"], [\"INFO\"])],\n",
    "    \"williams_2017\": [([\"bug\"], [\"BUG\"]), ([\"fea\"], [\"REQUEST\"]), ([\"oth\"], [\"OTHER\"])],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = \"./data/raw\"\n",
    "\n",
    "sanitized_dataset_names = [x.replace(\" \", \"_\").replace(\"#\", \"_\") for x in os.listdir(raw_data_dir)]\n",
    "\n",
    "sanitized_name_dict = {sanitized: original for original, sanitized in zip(os.listdir(raw_data_dir), sanitized_dataset_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chen_2014_facebook.xml\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa8 in position 231476: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9bdea973194a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxml_file_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mxml_str_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxml_str_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\temp\\python_envs\\clustering_env\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa8 in position 231476: invalid start byte"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "results = {}\n",
    "XML_dir = \"D:\\\\peter_devine_projects\\\\unsupervised-classification-benchmark\\\\data\\\\ar_doc_output\"\n",
    "comparison_dir = \"D:\\\\peter_devine_projects\\\\unsupervised-classification-benchmark\\\\data\\\\supervised_cls_preds\"\n",
    "\n",
    "for file in os.listdir(XML_dir):\n",
    "    \n",
    "    if file[-4:] != \".xml\":\n",
    "        continue\n",
    "    print(file)\n",
    "\n",
    "    xml_file_dir = os.path.join(XML_dir, file)\n",
    "\n",
    "    with open(xml_file_dir, \"r\", encoding=\"utf-8\") as f:\n",
    "        xml_str_data = f.read()\n",
    "        root = ET.fromstring(xml_str_data)\n",
    "\n",
    "    labelled_sentences = []\n",
    "\n",
    "    [labelled_sentences.extend(x.find(\"sentences\").findall(\"sentence\")) for x in root.findall(\"topic\")]\n",
    "\n",
    "    feedback_labels = {}\n",
    "\n",
    "    def extract_labels_for_sentences(sentence_tag):\n",
    "        label = sentence_tag.find(\"sentence_type\").text\n",
    "        origin_id = sentence_tag.find(\"from_review\").text\n",
    "\n",
    "        if origin_id in feedback_labels.keys():\n",
    "            feedback_labels[origin_id].append(label)\n",
    "        else:\n",
    "            feedback_labels[origin_id] = [label]\n",
    "\n",
    "    [extract_labels_for_sentences(x) for x in labelled_sentences]\n",
    "\n",
    "    feedback_labels = {k: list(set(v)) for k,v in feedback_labels.items()}\n",
    "\n",
    "    # Get the central repo that holds all the raw feedback data\n",
    "    raw_data_dir = \"./data/raw\"\n",
    "    \n",
    "    sanitized_csv_file_name = file[:-4] + \".csv\"\n",
    "    real_csv_name = sanitized_name_dict[sanitized_csv_file_name]\n",
    "\n",
    "    df = pd.read_csv(os.path.join(raw_data_dir, real_csv_name), index_col = 0)\n",
    "    df.labels = df.labels.str.strip(\"]\").str.strip(\"[\").str.split(\",\")\n",
    "    df.labels = df.labels.apply(lambda labels: [label.strip(\"\\\"\").strip(\"'\") for label in labels])\n",
    "    df.labels = df.labels.apply(lambda labels: [label.replace(\"'\", \"\").replace(\"\\\"\", \"\").strip() for label in labels])\n",
    "    print(df.labels.apply(lambda x: x[0]).unique())\n",
    "    \n",
    "    dataset_name = [dataset for dataset in label_maps.keys() if dataset in file][0]\n",
    "    label_map = label_maps[dataset_name]\n",
    "    \n",
    "    true_label_set = [labels[0] for labels in label_map]\n",
    "    prediction_label_set = [labels[1] for labels in label_map]\n",
    "    \n",
    "    df[\"surf_labels\"] = None\n",
    "    \n",
    "    for index, labels in feedback_labels.items():\n",
    "        df.loc[int(index), \"surf_labels\"] = labels\n",
    "        \n",
    "    df[\"surf_labels\"] = df[\"surf_labels\"].apply(lambda x: [\"OTHER\"] if x is None else x)\n",
    "    \n",
    "    df.to_csv(os.path.join(comparison_dir, file[:-4]+\".csv\"))\n",
    "    \n",
    "    true_labels = df.labels.apply(lambda x: [any([true_label in x for true_label in true_label_list]) for true_label_list in true_label_set])\n",
    "    pred_labels = df.surf_labels.apply(lambda x: [any([pred_label in x for pred_label in prediction_label_list]) for prediction_label_list in prediction_label_set])\n",
    "    \n",
    "    true_lab_arr = np.asarray(true_labels.values.reshape(-1).tolist())\n",
    "    pred_lab_arr = np.asarray(pred_labels.values.reshape(-1).tolist())\n",
    "    \n",
    "    # Only find ROC AUC value of labels that are contained in true labels\n",
    "    class_has_true_values = true_lab_arr.any(axis=0)\n",
    "    \n",
    "    if class_has_true_values.sum() < 1:\n",
    "        continue\n",
    "    \n",
    "    true_lab_arr = true_lab_arr[:, class_has_true_values]\n",
    "    pred_lab_arr = pred_lab_arr[:, class_has_true_values]\n",
    "    \n",
    "    roc_auc_score_val = roc_auc_score(true_lab_arr, pred_lab_arr)\n",
    "    \n",
    "    results[file[:-4]] = roc_auc_score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chen_2014_facebook': 0.5694599231371626,\n",
       " 'chen_2014_swiftkey': 0.5865985756093035,\n",
       " 'chen_2014_tapfish': 0.5872852355468396,\n",
       " 'chen_2014_templerun2': 0.5922563541777374,\n",
       " 'ciurumelea_2017_2048': 0.5625,\n",
       " 'ciurumelea_2017_Abstract_Art': 0.6605894105894106,\n",
       " 'ciurumelea_2017_AcDisplay': 0.48886174890083045,\n",
       " 'ciurumelea_2017_Adblock_Plus': 0.596153846153846,\n",
       " 'ciurumelea_2017_Amaze_File_Manager': 0.48897058823529416,\n",
       " 'ciurumelea_2017_Autostarts': 0.4858585858585859,\n",
       " 'ciurumelea_2017_A_Comic_Viewer': 0.4950809592129535,\n",
       " 'ciurumelea_2017_BatteryBot_Battery_Indicator': 0.6522988505747127,\n",
       " 'ciurumelea_2017_Calculator': 0.6017374517374516,\n",
       " 'ciurumelea_2017_CatLog': 0.6254901960784314,\n",
       " 'ciurumelea_2017_Duck_Duck_GO': 0.652139037433155,\n",
       " 'ciurumelea_2017_Financius_-_Expense_Manager': 0.4375,\n",
       " 'ciurumelea_2017_Muzei_Live_Wallpaper': 0.65,\n",
       " 'ciurumelea_2017_Turbo_Editor_(_Text_Editor_)': 0.16666666666666669,\n",
       " 'ciurumelea_2017_Tweet_Lanes': 0.375,\n",
       " 'ciurumelea_2017_Wally': 0.6071428571428571,\n",
       " 'ciurumelea_2017_Xabber': 0.5,\n",
       " 'di_sorbo_2016_blinq_summary': 0.8130252485609628,\n",
       " 'di_sorbo_2016_cstp_summary': 0.8571428571428572,\n",
       " 'di_sorbo_2016_doodlePairs_summary': 0.9285714285714286,\n",
       " 'di_sorbo_2016_karaokeFree_summary': 0.9131944444444444,\n",
       " 'di_sorbo_2016_karaokePaid_summary': 0.8920757922474168,\n",
       " 'di_sorbo_2016_lifelog_summary': 0.8535632183908046,\n",
       " 'di_sorbo_2016_minesweeperReloaded_summary': 0.8870214752567693,\n",
       " 'di_sorbo_2016_movieCreator_summary': 0.8902207288835196,\n",
       " 'di_sorbo_2016_picturexAndroid_summary': 0.9285714285714286,\n",
       " 'di_sorbo_2016_picturexWindowsPhone_summary': 0.875,\n",
       " 'di_sorbo_2016_powernApp_summary': 0.8713307392550267,\n",
       " 'di_sorbo_2016_sheepOblock_summary': 0.921875,\n",
       " 'di_sorbo_2016_sketch_summary': 0.8791666666666667,\n",
       " 'di_sorbo_2016_stoneFlood_summary': 0.7709854832618788,\n",
       " 'di_sorbo_2016_trackID_summary': 0.8578853332939049,\n",
       " 'di_sorbo_2016_video_summary': 0.8592307297973969,\n",
       " 'di_sorbo_2016_weightTrack_summary': 0.9055555555555556,\n",
       " 'di_sorbo_2016_wifiFileTransfer_summary': 0.914546783625731,\n",
       " 'guzman_2015_Angrybirds': 0.6849525357264808,\n",
       " 'guzman_2015_Dropbox': 0.6634365781698557,\n",
       " 'guzman_2015_Evernote': 0.7002319680777889,\n",
       " 'guzman_2015_Picsart': 0.6649334220416159,\n",
       " 'guzman_2015_Pininterest': 0.6800356935718577,\n",
       " 'guzman_2015_Tripadvisor': 0.6581027091687739,\n",
       " 'guzman_2015_Whatsapp': 0.6796612898793524,\n",
       " 'maalej_2016_310947683': 1.0,\n",
       " 'maalej_2016_403692190': 0.5,\n",
       " 'maalej_2016__10_Fotocollage_Bildbearbeitung': 0.5,\n",
       " 'maalej_2016__10_line_gratis_anrufe': 0.5,\n",
       " 'maalej_2016__1_Camera_Zoom_FX': 0.46648550724637683,\n",
       " 'maalej_2016__1_OfficeSuite_Pro_7__(PDF_und_HD)': 0.49722222222222223,\n",
       " 'maalej_2016__1_PicsArt_-_Photo_Studio': 0.4523809523809524,\n",
       " 'maalej_2016__2_flipagram': 0.5511111111111111,\n",
       " 'maalej_2016__3_Need_for_Speed_Most_Wanted': 0.5241477272727273,\n",
       " 'maalej_2016__3_Seitenmanager': 0.6039107289107288,\n",
       " 'maalej_2016__3_skype': 0.49124999999999996,\n",
       " 'maalej_2016__4_antivirus_GRATIS': 0.8333333333333333,\n",
       " 'maalej_2016__5_Plants_vs_Zombies': 0.3397129186602871,\n",
       " 'maalej_2016__5_viber': 0.6,\n",
       " 'maalej_2016__6_Assassins_Creed_Pirates': 0.5454545454545454,\n",
       " 'maalej_2016__6_firefox': 0.40909090909090906,\n",
       " 'maalej_2016__6_MomentCam': 0.46411483253588515,\n",
       " 'maalej_2016__6_Photo_Studio_PRO': 0.46875,\n",
       " 'maalej_2016__7_Worms_2_Armageddon': 0.4642857142857143,\n",
       " 'maalej_2016__8_gmx_mail': 0.5,\n",
       " 'maalej_2016__8_Wo_ist_mein_Wasser': 0.46875,\n",
       " 'maalej_2016__8_XDA_Premium': 0.375,\n",
       " 'maalej_2016__9_Modern_Combat_4_Zero_Hour': 0.5197368421052632,\n",
       " 'maalej_2016__9_Perfect365_Gesichts-Make-Up': 0.5,\n",
       " 'scalabrino_2017_acr.browser.barebones': 0.6446428571428572,\n",
       " 'scalabrino_2017_air.hmbtned': 0.5729166666666666,\n",
       " 'scalabrino_2017_com.alfray.timeriffic': 0.7333333333333334,\n",
       " 'scalabrino_2017_com.duckduckgo.mobile.android': 0.5357808857808858,\n",
       " 'scalabrino_2017_com.ebay.mobile': 0.6155242090493214,\n",
       " 'scalabrino_2017_com.google.zxing.client.android': 0.6717414529914529,\n",
       " 'scalabrino_2017_com.ringdroid': 0.6023601398601399,\n",
       " 'scalabrino_2017_com.uberspot.a2048': 0.75,\n",
       " 'scalabrino_2017_com.viber.voip': 0.5197947214076246,\n",
       " 'scalabrino_2017_edu.berkeley.boinc': 0.5342320261437908,\n",
       " 'scalabrino_2017_org.dolphinemu.dolphinemu': 0.5723134708428825,\n",
       " 'scalabrino_2017_org.linphone': 0.5681623931623931,\n",
       " 'scalabrino_2017_org.wordpress.android': 0.7001633986928104,\n",
       " 'tizard_2019_features': 0.5886219160351085,\n",
       " 'tizard_2019_fire_fox': 0.5774764471271272,\n",
       " 'tizard_2019_issue': 0.5622292578062555,\n",
       " 'williams_2017_@android': 0.5999575263577325,\n",
       " 'williams_2017_@callofduty': 0.5867500623893979,\n",
       " 'williams_2017_@googlechrome': 0.6001135516893469,\n",
       " 'williams_2017_@instagram': 0.5980235779520585,\n",
       " 'williams_2017_@minecraft': 0.6432079917299842,\n",
       " 'williams_2017_@snapchat': 0.5488527794790494,\n",
       " 'williams_2017_@visualstudio': 0.5805517515442169,\n",
       " 'williams_2017_@whatsapp': 0.640692615020336,\n",
       " 'williams_2017_@windows': 0.5722567232574112}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cos = pd.read_csv(\"./results/roc_auc_cosine.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [x[:-3] for x in os.listdir(\"./data/downloaders\") if x[-3:] == \".py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_dataset_results(results_df):    \n",
    "    return [results_df[[col for col in results_df.columns if dataset_name in col]].T.mean() for dataset_name in dataset_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_mean = pd.DataFrame(get_per_dataset_results(results_cos), index=dataset_names)[\"bert_large_nli_mean_tokens.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_doc = pd.DataFrame(get_per_dataset_results(pd.DataFrame({\"AR-Doc\": results}).T), index=dataset_names)[\"AR-Doc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s-bert</th>\n",
       "      <th>AR-doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chen_2014</th>\n",
       "      <td>0.669321</td>\n",
       "      <td>0.583900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ciurumelea_2017</th>\n",
       "      <td>0.681986</td>\n",
       "      <td>0.532117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>di_sorbo_2016</th>\n",
       "      <td>0.661210</td>\n",
       "      <td>0.878831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guzman_2015</th>\n",
       "      <td>0.758384</td>\n",
       "      <td>0.675908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maalej_2016</th>\n",
       "      <td>0.785870</td>\n",
       "      <td>0.523947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scalabrino_2017</th>\n",
       "      <td>0.666580</td>\n",
       "      <td>0.616997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tizard_2019</th>\n",
       "      <td>0.649695</td>\n",
       "      <td>0.576109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>williams_2017</th>\n",
       "      <td>0.587251</td>\n",
       "      <td>0.596712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   s-bert    AR-doc\n",
       "chen_2014        0.669321  0.583900\n",
       "ciurumelea_2017  0.681986  0.532117\n",
       "di_sorbo_2016    0.661210  0.878831\n",
       "guzman_2015      0.758384  0.675908\n",
       "maalej_2016      0.785870  0.523947\n",
       "scalabrino_2017  0.666580  0.616997\n",
       "tizard_2019      0.649695  0.576109\n",
       "williams_2017    0.587251  0.596712"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"s-bert\": bert_mean.values, \"AR-doc\": ar_doc.values}, index=dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66932053, 0.68198576, 0.66121034, 0.75838379, 0.7858703 ,\n",
       "       0.66657966, 0.64969485, 0.58725089])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_mean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58390002],\n",
       "       [0.53211707],\n",
       "       [0.87883127],\n",
       "       [0.67590774],\n",
       "       [0.52394739],\n",
       "       [0.61699735],\n",
       "       [0.57610921],\n",
       "       [0.59671184]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_doc.values.resa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_sorbos = [x for x in os.listdir(\"./data/raw\") if \"di_sorbo\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [pd.read_csv(os.path.join(raw_data_dir, di), index_col = 0).shape for di in di_sorbos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x[0] for x in sizes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
